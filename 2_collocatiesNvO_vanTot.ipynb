{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Collocatie - het tellen van woorden in de buurt van een term\n",
    "Net als bij een concordantie richt een collocatie-analyse zich op de context van specifieke zoektermen. Het verschil is dat bij een collocatie-analyse alle woorden in de context worden geteld. Op deze manier kan er een beeld ontstaan van de woorden die veel in de omgeving van een specifieke zoekterm worden gebruikt. \n",
    "\n",
    "In de code hieronder verwijst `search_term` weer naat de term waarnaar wordt gezocht, en `window` bepaalt weer het aantal woorden voor en na de opgegeven zoekterm.\n",
    "\n",
    "In de onderstaande code wordt ook de functie 'removeStopwords()' gebruikt. Deze functie heeft als effect dat de woorden die in alle documenten gemiddeld genomen even vaak voorkomen (bv. de, het, een wij, zijn, hebben, geweest, allen, doen, ik, jullie, etc.) en dus niet onderscheidend zijn voor een bepaald document, verwijderd worden. \n",
    "\n",
    "De onderstaande code zoekt in het gehele corpus, dat uit ca. 600 egodocumenten bestaat, en het uitvoeren van de code kan daarom enige tijd in beslag nemen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "De volgende woorden komen het vaakste voor bij joden: \n",
      "\n",
      "mensen =>  15\n",
      "oorlog =>  15\n",
      "nederlandse =>  12\n",
      "men =>  10\n",
      "wordt =>  9\n",
      "duitse =>  9\n",
      "onderduikers =>  9\n",
      "i =>  9\n",
      "wereldoorlog =>  8\n",
      "joodse =>  8\n",
      "grote =>  8\n",
      "zien =>  8\n",
      "mm =>  8\n",
      "transport =>  7\n",
      "nederland =>  7\n",
      "jaar =>  7\n",
      "maken =>  7\n",
      "één =>  7\n",
      "aantal =>  7\n",
      "tweede =>  6\n",
      "israël =>  6\n",
      "tijd =>  6\n",
      "bekend =>  6\n",
      "dood =>  6\n",
      "kwam =>  6\n",
      "sinti =>  6\n",
      "palestina =>  5\n",
      "veel =>  5\n",
      "iets =>  5\n",
      "films =>  5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import re\n",
    "import pandas as pd\n",
    "from kitlvTdm import *\n",
    "\n",
    "# Maak drie variabelen, de dir (directory/map) corpus, de zoekterm 'baboe', en de search window: 30/\n",
    "\n",
    "path = 'Corpus'\n",
    "searchTerm = 'joden'\n",
    "window = 30\n",
    "\n",
    "min_year = 1900\n",
    "max_year = 1950\n",
    "\n",
    "# Maak een dictionary corpusFreq (een variabele die werkt in de vorm {key : value, key : value})\n",
    "corpusFreq = dict()\n",
    "\n",
    "# Voor ieder bestand in de map in de variabele dir ('corpus')\n",
    "for i, file in enumerate(os.listdir( path )):\n",
    "    \n",
    "    # Bereken en toon het percentage van de boeken dat is gelezen\n",
    "    percentage_done = i / len(os.listdir(path)) * 100\n",
    "    print(\"percentage done: {:.2f}%\".format(percentage_done), end = \"\\r\")\n",
    "    \n",
    "    # Als het bestand een tekst bestand is:\n",
    "    if re.search( '[.]txt$' , file ):\n",
    "        year = showYear(file)\n",
    "\n",
    "        # Hier wordt gecheckt er een jaar van het boek bekent is en het jaar uit 4 tekens bestaat.\n",
    "        if year != \"\" and len(year) == 4:\n",
    "            year = int(year) # Zo ja: maak er een nummer ipv tekst van\n",
    "\n",
    "            # Hier wordt gecheckt of het jaar van het boek in de periode valt.\n",
    "            if year >= min_year and year <= max_year:\n",
    "                \n",
    "                # Vind de frequencies van alle woorden die voorkomen in de buurt van de zoekterm. Sla ze op in de variabele freq\n",
    "                # \"In de buurt\" wordt dus aangegeven door de variabele 'window'\n",
    "                freq = collocation( join( path , file ) , searchTerm , window )\n",
    "\n",
    "                # Verwijder de stopwoorden uit de gevonden collocaties \n",
    "                freq = removeStopwords( freq )\n",
    "\n",
    "                \n",
    "                # Voeg de gevonden collocaties zonder stopwoorden toe aan de variabele corpusFreq.\n",
    "                for word in freq:\n",
    "                    if word  in corpusFreq: # Als het woord al in corpusFreq staat: tel extra aantal erbij op\n",
    "                        corpusFreq[word] += freq[word]\n",
    "                    else: # anders, plaats het woord in corpusFreq\n",
    "                        corpusFreq[word] = freq[word]\n",
    "        \n",
    "        \n",
    "# Het aantal collocaties dat je wilt laten zien\n",
    "max = 30\n",
    "\n",
    "# De teller die bijhoudt hoeveel collocaties er zijn getoond.\n",
    "i = 0\n",
    "\n",
    "# Als er collocaties zijn gevonden:\n",
    "if len(corpusFreq)> 0:\n",
    "\n",
    "    # Sorteer de collocaties van hoog naar laag. \"key = lambda x: corpusFreq[x]\" is nodig voor het juist sorteren aangezien de\n",
    "    # frequenties opgeslagen zijn in een dictionary (een data type). \"reverse = True\" zorgt ervoor het van hoog naar laag \n",
    "    # is gesorteerd (ipv de automatische laag naar hoog).\n",
    "    corpusFreqSorted = sorted(corpusFreq, key = lambda x: corpusFreq[x], reverse = True)\n",
    "\n",
    "    print( f'De volgende woorden komen het vaakste voor bij { searchTerm }: \\n' )\n",
    "\n",
    "    # Print het volgendende waarbij searchTerm de eerder gedefinieerde zoekterm is\n",
    "\n",
    "    for f in corpusFreqSorted:\n",
    "        i += 1\n",
    "\n",
    "        # Voor iedere collocatie in de van hoog naar laag gesorteerde frequenties\n",
    "        # Teller plus 1\n",
    "        # Laat het woord en de frequentie zien waarmee het voorkomt in de buurt van de zoekterm\n",
    "        print( '{} =>  {}'.format( f , corpusFreq[f] ) )\n",
    "\n",
    "\n",
    "\n",
    "        # Als er \"max\" (hierboven gedefinieerd) collocatie frequenties zijn getoond:\n",
    "        # Stop met laten zien\n",
    "        if i == max: \n",
    "            break\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "           \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wanneer je de code voor de collocatie-analyse hebt uitgevoerd kun je het resultaat opslaan met de code in de onderstaande cel. Deze code maakt een bestand aan met de naam 'collocation.csv' waarin de woorden en de frequenties terug te vinden zijn. \n",
    "\n",
    "# BESTANDS NAAM VERANDEREN IN DEZE TEKST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file saved as joden-collocation_1900_2500.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import re\n",
    "import pandas as pd\n",
    "from kitlvTdm import *\n",
    "\n",
    "# Maximaal aantal woorden waarvan de frequentie wordt opgeslagen in excel bestand, gesorteerd van hoog naar laag.\n",
    "max = 30\n",
    "\n",
    "# De naam van het bestand dat wordt opgeslagen.\n",
    "outFile = 'joden-collocation'\n",
    "\n",
    "## VOOR STEF: het kan ook automatisch als:\n",
    "outFile = f'{searchTerm}-collocation'\n",
    "\n",
    "# Maak een Pandas DataFrame, een soort tabel met extra functionaliteit, met gespecificeerde kolom namen.\n",
    "df = pd.DataFrame(columns = [\"term\", \"frequency\"])\n",
    "\n",
    "# Een teller die op nul staat.\n",
    "count = 0\n",
    "\n",
    "# Voor ieder woord in de van hoog naar laag gesorteerde frequenties.\n",
    "for f in corpusFreqSorted:\n",
    "    \n",
    "    # Voeg een rij toe aan het dataframe met de volgende structuur: {\"naam van de kolom\"} : waarde.\n",
    "    df = df.append({\"term\" : f, \"frequency\" : corpusFreq[f]}, ignore_index = True)\n",
    "    \n",
    "    # Tel een op bij de teller\n",
    "    count += 1\n",
    "    \n",
    "    # als het maximaal aantal woorden zijn toegevoegd aan het dataframe stop met toevoegen.\n",
    "    if count == max:\n",
    "        break\n",
    "        \n",
    "# Sla het DataFrame op als excel bestand.\n",
    "df.to_excel(f\"{outFile}_{min_year}_{max_year}.xlsx\")\n",
    "print(f\"Excel file saved as {outFile}_{min_year}_{max_year}.xlsx\" )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Oefening 2: Voer een collocatie-analyse uit, aan de hand van een zoekterm die van belang kan zijn voor jouw onderzoek. Experimenteer met verschillende waarden voor de variabelen `search_term`, `window`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
